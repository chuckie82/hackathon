{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tif\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total files = 172\n",
      "number of dark files = 20\n"
     ]
    }
   ],
   "source": [
    "def read_tif_files():\n",
    "    '''function to read out tif files in directory'''\n",
    "    #usr_in = input('Please give path to where is your data located at:  ')\n",
    "    f_list = list(glob.iglob('/Users/timothyliu/Desktop/Globus/multimodal/data3_Textured/**/*.tif', recursive=True))\n",
    "    dark_list = list(glob.iglob('/Users/timothyliu/Desktop/Globus/multimodal/data3_Textured/**/*dark*.tif', recursive=True))\n",
    "    for el in f_list:\n",
    "        if el in dark_list:\n",
    "            f_list.remove(el)\n",
    "    #out_list = [f for f in f_list if f not in dark_list]\n",
    "    print('number of total files = {}'.format(len(list(f_list))))\n",
    "    print('number of dark files = {}'.format(len(list(dark_list))))\n",
    "    return list(f_list)\n",
    "# doesn't have to do this step, once we have f_list\n",
    "f_list = read_tif_files()\n",
    "#print(f_list)\n",
    "with open('/Users/timothyliu/hackathon/texture_f_list.txt', 'w') as f:\n",
    "    json.dump(f_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/timothyliu/Desktop/Globus/multimodal/clean_data/CeO2_calib-00000.tif',\n",
       " '/Users/timothyliu/Desktop/Globus/multimodal/clean_data/Ni_300K-00044.tif',\n",
       " '/Users/timothyliu/Desktop/Globus/multimodal/clean_data/Ni_STD_300K-00538.tif',\n",
       " '/Users/timothyliu/Desktop/Globus/multimodal/clean_data/nickel-00000.raw.tif',\n",
       " '/Users/timothyliu/Desktop/Globus/multimodal/clean_data/nickel_296K-00002.tif',\n",
       " '/Users/timothyliu/Desktop/Globus/multimodal/clean_data/nickelstandard_100K-00028.tif']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect clean data\n",
    "std_list = list(glob.glob('/Users/timothyliu/Desktop/Globus/multimodal/clean_data/*.tif'))\n",
    "dark_list = []\n",
    "for el in std_list:\n",
    "    if 'dark' in el:\n",
    "        dark_list.append(el)\n",
    "        std_list.remove(el)\n",
    "std_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_list = list(glob.glob('/Users/timothyliu/Desktop/Globus/multimodal/clean_data/**/*.tif'))\n",
    "with open('/Users/timothyliu/hackathon/std_f_list.txt', 'w') as std_f:\n",
    "    json.dump(std_list, std_f)\n",
    "with open('/Users/timothyliu/hackathon/extra_std_f_list.txt', 'w') as add_f:\n",
    "    json.dump(add_list, add_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start to work\n",
    "os.chdir('/Users/timothyliu/hackathon/')\n",
    "# read in json file\n",
    "with open('texture_f_list.txt','r') as f:\n",
    "    f_list = json.load(f)\n",
    "with open('std_f_list.txt','r') as f:\n",
    "    std_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# brutally corp images\n",
    "def quarter_img(f_name, center=1024, width=200):\n",
    "    img = tif.imread(f_name)\n",
    "    img_list = []\n",
    "    for i in np.linspace(-1,1,2):\n",
    "        for j in np.linspace(-1,1,2):\n",
    "            lower_x = min(center+int(i)*width, center)\n",
    "            upper_x = max(center+int(i)*width, center)\n",
    "            lower_y = min(center+int(j)*width, center)\n",
    "            upper_y = max(center+int(j)*width, center)\n",
    "            img_list.append(img[lower_x:upper_x, lower_y:upper_y])\n",
    "    return img_list\n",
    "\n",
    "def crop_img(f_name, center=1024, width=200):\n",
    "    img = tif.imread(f_name)\n",
    "    img_list = []\n",
    "    img_list.append(img[center-width:center+width, center-width:center+width])\n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loop over images and create np array of texture data\n",
    "def file_dict(f_list):\n",
    "    out_dict = {}\n",
    "    for i in range(len(f_list)):\n",
    "        out_dict.update({str(i):os.path.basename(f_list[i])})\n",
    "        #print(os.path.basename(f_list[i]))\n",
    "    return out_dict\n",
    "        \n",
    "def build_quarter_img_list(f_list):\n",
    "    import tifffile as tif\n",
    "    out_list = []\n",
    "    #f_out_dict = []\n",
    "    _img = tif.imread(f_list[1])\n",
    "    num_obs = len(f_list)\n",
    "    (x_dim, y_dim) = np.shape(_img)\n",
    "    for i in range(len(f_list)):\n",
    "        quarter_imgs = quarter_img(f_list[i])\n",
    "        for el in quarter_imgs:\n",
    "            out_list.append(el)\n",
    "            #f_out_dict.append(str(i))\n",
    "    out = np.array(out_list)\n",
    "    return out #,f_out_list\n",
    "\n",
    "def build_full_img_list(f_list):\n",
    "    import tifffile as tif\n",
    "    out_list = []\n",
    "    _img = tif.imread(f_list[1])\n",
    "    num_obs = len(f_list)\n",
    "    (x_dim, y_dim) = np.shape(_img)\n",
    "    for f in f_list:\n",
    "        img = crop_img(f)\n",
    "        out_list.append(img)\n",
    "    _out = np.array(out_list)\n",
    "    out = np.squeeze(_out)\n",
    "    return out #,f_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# quarter_imgs\n",
    "quarter_texture_data_list = build_quarter_img_list(f_list)\n",
    "quarter_standard_list = build_quarter_img_list(std_list)\n",
    "quarter_extra_standard_list = build_quarter_img_list(add_list)\n",
    "\n",
    "# save data\n",
    "#os.makedirs('/Users/timothyliu/hackathon/quarter/', exist_ok=True)\n",
    "#np.save('/Users/timothyliu/hackathon/quarter/texture_data_np_array',quarter_texture_data_list)\n",
    "#np.save('/Users/timothyliu/hackathon/quarter/standard_data_np_array', quarter_standard_list)\n",
    "#np.save('/Users/timothyliu/hackathon/quarter/extra_standard_data_np_array', quarter_extra_standard_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(688, 200, 200)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quarter_texture_data_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_dict = file_dict(f_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# full imgs\n",
    "texture_data_list = build_full_img_list(f_list)\n",
    "standard_list = build_full_img_list(std_list)\n",
    "extra_standard_list = build_full_img_list(add_list)\n",
    "\n",
    "# save data\n",
    "#os.makedirs('/Users/timothyliu/hackathon/full/', exist_ok=True)\n",
    "#np.save('/Users/timothyliu/hackathon/full/texture_data_np_array', texture_data_list)\n",
    "#np.save('/Users/timothyliu/hackathon/full/standard_data_np_array', standard_list)\n",
    "#np.save('/Users/timothyliu/hackathon/full/extra_standard_data_np_array', extra_standard_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== For data set1: 172*4 textured data and 26*4 untextured data ===\n",
      "accuracy of textured testing set = 0.9811405745836405\n",
      "accuracy of untextured testing set = 0.9731687020399783\n",
      "fp_list = [8, 12, 29, 31, 36, 37, 38, 39, 43, 47, 173, 175, 177, 179, 299, 324, 399]\n",
      "fn_list = []\n",
      "fp_mean_eps = 0.018859425577804283\n",
      "fn_mean_eps = 0.026831298181326103\n"
     ]
    }
   ],
   "source": [
    "print('=== For data set1: 172*4 textured data and 26*4 untextured data ===')\n",
    "# get file label\n",
    "labels = np.load('/Users/timothyliu//hackathon/labels.npy')\n",
    "predicted = np.load('/Users/timothyliu//hackathon/predicted_output.npy')\n",
    "#print(labels.shape,predicted.shape)\n",
    "\n",
    "machine_guess_textured = np.mean(predicted[:299,0], axis=0)\n",
    "machine_guess_untextured = np.mean(predicted[299:,1], axis=0)\n",
    "print(\"accuracy of textured testing set = {}\".format(machine_guess_textured))\n",
    "print(\"accuracy of untextured testing set = {}\".format(machine_guess_untextured))\n",
    "\n",
    "# false positive ind: texture but classified as untextured\n",
    "texture_range = 299\n",
    "fp_mean_eps_1 = np.mean(predicted[:299,1], axis=0)\n",
    "fn_mean_eps_1 = np.mean(predicted[299:,0], axis=0)\n",
    "fp_list_1 = []\n",
    "for i in range(texture_range):\n",
    "    predict_label = predicted[i]\n",
    "    if predict_label[1] > fp_mean_eps_1:\n",
    "        fp_list_1.append(i)\n",
    "        \n",
    "# false negative ind: untextured but classified as textured\n",
    "fn_list_1 = []\n",
    "for i in range(texture_range,np.shape(predicted)[0]):\n",
    "    predict_label = predicted[i]\n",
    "    if predict_label[0] > fn_mean_eps_1:\n",
    "        fp_list_1.append(i)\n",
    "        \n",
    "print('fp_list = {}'.format(fp_list_1))\n",
    "print('fn_list = {}'.format(fn_list_1))\n",
    "print('fp_mean_eps = {}'.format(fp_mean_eps_1))\n",
    "print('fn_mean_eps = {}'.format(fn_mean_eps_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AuOnCu_bkg_RT-00002.tif', 'AuOnCu_bkg_RT-00003.tif', 'AuOnCu_bkg_RT-00007.tif', 'AuOnCu_bkg_RT-00007.tif', 'AuOnCu_bkg_RT-00010.tif', 'AuOnCu_bkg_RT-00010.tif', 'AuOnCu_bkg_RT-00010.tif', 'AuOnCu_bkg_RT-00010.tif', 'AuOnCu_bkg_RT-00011.tif', 'AuOnCu_bkg_RT-00012.tif', 'CL-PF-3_RT-00005.tif', 'CL-PF-3_RT-00005.tif', 'CL-PF-3_RT-00006.tif', 'CL-PF-3_RT-00006.tif', 'CL-TF-2_RT-00003.tif', 'CL-TF-2_RT-00010.tif', 'Cu_in_polyester_225um_bkg_final-00009.tif']\n"
     ]
    }
   ],
   "source": [
    "print('wrongly labeled file name')\n",
    "wrong_file = []\n",
    "for el in fp_list_1:\n",
    "    _ind = int(el/4)\n",
    "    wrong_file.append(f_dict[str(_ind)])\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2) (2000, 2)\n",
      "0.753455182532\n",
      "0.60883660159\n",
      "len cropped fp_list = 307\n",
      "len cropped fn_list = 0\n",
      "cropped fp_mean_eps = 0.15933270794556256\n",
      "cropped fn_mean_eps = 0.05077463737171928\n"
     ]
    }
   ],
   "source": [
    "# get file label\n",
    "labels = np.load('/Users/timothyliu//hackathon/labels_crpped.npy')\n",
    "predicted = np.load('/Users/timothyliu//hackathon/predicted_output_cropped.npy')\n",
    "print(labels.shape,predicted.shape)\n",
    "\n",
    "machine_guess_textured = np.mean(predicted[:299,0], axis=0)\n",
    "machine_guess_untextured = np.mean(predicted[299:,1], axis=0)\n",
    "print(\"accuracy of textured testing set = {}\".format(machine_guess_textured))\n",
    "print(\"accuracy of untextured testing set = {}\".format(machine_guess_untextured))\n",
    "\n",
    "# false positive ind: texture but classified as untextured\n",
    "texture_range = 999\n",
    "fp_mean_eps = np.mean(predicted[:999,1], axis=0)\n",
    "fn_mean_eps = np.mean(predicted[999:,0], axis=0)\n",
    "fp_list = []\n",
    "for i in range(texture_range):\n",
    "    predict_label = predicted[i]\n",
    "    if predict_label[1] > fp_mean_eps:\n",
    "        fp_list.append(i)\n",
    "        \n",
    "# false negative ind: untextured but classified as textured\n",
    "fn_list = []\n",
    "for i in range(texture_range,np.shape(predicted)[0]):\n",
    "    predict_label = predicted[i]\n",
    "    if predict_label[0] > fp_mean_eps:\n",
    "        fp_list.append(i)\n",
    "        \n",
    "print('len cropped fp_list = {}'.format(len(fp_list)))\n",
    "print('len cropped fn_list = {}'.format(len(fn_list)))\n",
    "print('cropped fp_mean_eps = {}'.format(fp_mean_eps))\n",
    "print('cropped fn_mean_eps = {}'.format(fn_mean_eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
